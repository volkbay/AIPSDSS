loss = [0.514412
0.272280
0.150672
0.108158
0.062546
0.058278
 0.027409
 0.055003
 0.024240
 0.064392
 0.048987
 0.033239
];
loss2 = [0.545299
0.285499
0.167898
0.109100
0.071459
0.072415
 0.048740
 0.056779
 0.029078
 0.046463
 0.029907
 0.036110
 0.032193
 0.015440
 0.022193
 0.024627
 0.036913
 0.036324
 0.028556
 0.022543
 0.010616
 0.053716
 0.016277
 0.031072
 0.005319
 0.062334
 0.005951
 0.022549
 0.013010
 0.017921
 0.017479
 0.047933
 0.006942
 0.028462
 0.022033
 0.017757
 0.019305
 0.027214
 0.022688
 0.035099
 0.031830
 0.013661
 0.022615
 0.015678
 0.031484
 0.028633
 0.019599
 0.012504
 0.034258
 0.043792
 0.016204
 0.021677
 0.033113
 0.011450
 0.008566
 0.020746
 0.029406
 0.027366
 0.014711
 0.009307
 0.012653
 0.014575
];
loss3=[0.683522
0.410695
0.225957
0.142794
0.097296
0.061476
0.054220
0.047013
0.022569
0.026388
0.024506
0.037410
0.029411
0.044334
0.021112
0.044064
0.038520
0.032417
0.019427
0.025448
0.016594
0.015422
0.033926
0.030122
0.026556
0.047848
0.022501
0.037950
0.012168
0.017190
0.011604
0.062488
0.037429
0.027359
0.018442
0.032888
0.025943
0.030505
0.026620
0.014976
0.022558
0.013463
0.018988
0.022495
0.019498
0.016779
0.035799
0.030030
0.019943
0.027342
0.018826
0.042322
0.043187
0.013629
0.009454
0.016498
0.029777
0.033811
0.035293
0.018700
0.019512
0.015113
 0.022685
 0.018748
 0.014739
 0.011896
 0.029684
 0.008722
 0.014827
 0.028115
 0.017411
 0.028545
 0.016652
 0.018419
 0.010773
 0.025963
 0.017043
 0.032319
 0.007529
 0.006350
 0.008861
 0.007262
 0.019126
 0.008435
 0.018280
 0.022359
 0.012268
 0.016271
 0.012109
 0.013772
 0.011434
 0.005775
 0.014124
 0.021153
 0.013148
 0.025940
 0.008827
 0.025755
 0.016534
 0.026068
 0.013359
 0.023575
 0.021445
 0.007558
 0.021684
 0.045617
 0.015629
 0.009720
 0.023507
 0.017161
 0.010415
 0.012087
 0.032421
 0.013403
 0.012688
 0.012044
 0.015184
 0.006808
 0.009521
 0.015310
 0.034821
 0.014180
 0.012756
 0.015191
 0.014865
 0.007668
 0.020302
 0.018911
 0.016436
 0.016158
 0.024971
 0.023198
 0.011569
 0.017139
 0.004177
 0.019643
 0.005519
 0.025082
 0.014106
 0.010388
 0.016047
 0.023778
 0.005671
 0.021264
 0.013359
 0.008624
 0.022654
 0.012228
 0.021401
 0.012459
 0.012270
 0.009158
 0.015376
 0.011803
 0.020634
 0.017490
 0.015531
 0.011213
 0.006976
 0.018359
 0.020475
 0.023104
 0.017297
 0.008054
 0.019918
 0.015577
 0.018564
 0.012478
 0.007784
 0.012051
 0.023967
 0.010182
 0.011542
 0.005675
 0.017512
 0.010288
 0.008010
 0.012005
 0.008650
 0.005968
 0.016643
 0.016597
 0.018226
 0.010966
 0.016245
 0.016493
 0.021544
 0.017712
 0.013769
 0.019420
 0.010952
 0.015841
 0.003757
 0.013972
 0.015622
 0.010523
 0.022813
 0.006587
 0.006406
 0.009138
 0.014871
 0.028293
 0.017717
 0.014654
 0.016861
 0.016344
 0.017165
 0.007421
 0.007664
 0.019850
 0.013081
 0.009026
 0.008151
 0.005085
 0.008457
 0.021379
 0.014046
 0.014283
 0.014354
 0.006716
 0.013030
 0.020715
 0.007900
 0.009667
 0.021352
 0.011259
 0.011299
 0.006254
 0.006906
 0.011015
 0.020733
 0.016526
 0.010123
 0.006331
 0.008353
 0.007366
 0.023905
 0.008863
 0.011658
 0.007703
 0.010826
 0.015630
 0.016174
 0.016483
 0.003269
 0.005991
 0.016291
 0.006841
 0.014403
 0.007707
 0.016913
 0.014730
 0.014560
 0.013218
 0.008194
 0.011053
 0.010350
 0.005592
 0.008792
 0.009604
 0.008071
 0.031592
 0.008521
 0.008210
 0.016494
 0.012440
 0.009338
 0.010675
 0.019944
 0.004637
 0.009280
 0.011081
 0.007984
 0.008129
 0.011787
 0.011528
 0.009278
 0.011777
 0.015956
 0.005995
 0.006752
 0.023047
 0.006589
 0.005153
 0.008765
 0.023315
 0.007038
 0.008105
 0.007505
 0.017779
 0.018231
 0.010070
 0.008270
 0.015714
 0.008196
 0.007263
 0.016147
 0.005339
 0.006082
 0.014686
 0.005783
 0.012205
 0.018774
 0.007561
 0.006628
 0.003870
 0.008738
 0.007964
 0.006465
 0.003765
 0.017490
 0.008306
 0.006367
 0.006957
 0.003474
 0.012514
 0.012400
 0.004603
 0.010032
 0.014180
 0.016352
 0.006373
 0.010765
 0.007908
 0.012132
 0.004487
 0.018369
 0.020235
 0.017289
 0.008723
 0.009568
 0.021873
 0.008444
 0.026568
 0.014000
 0.007172
 0.007208
 0.005766
 0.009691
 0.027616
 0.017268
 0.013804
 0.009900
 0.026666
 0.003391
 0.018844
 0.017536
 0.012674
 0.019014
 0.007376
 0.021925
 0.008245
 0.014000
 0.014320
 0.021378
 0.009731
 0.007483
 0.004626
 0.016954
 0.015768
 0.009293
 0.014560
 0.015449
 0.005905
 0.020404
 0.007815
 0.017112
 0.011761
 0.005096
 0.002652
 0.016699
 0.038120
 0.016279
 0.026913
 0.029280
 0.012949
 0.004658
 0.020083
 0.002054
 0.006748
 0.018047
 0.016677
 0.015419
 0.015319
 0.008680
 0.019907
 0.008153
 0.002508
 0.015124
 0.017878
 0.011690
 0.028086
 0.012602
 0.010150
 0.032490
 0.026005
 0.028535
 0.011278
 0.011811
 0.010740
 0.008281
 0.015393
 0.010041
 0.010256
 0.004194
 0.011010
 0.019047
 0.025869
 0.025566
 0.015817
 0.026512
 0.016582
 0.014490
 0.010674
 0.007401
 0.040739
 0.013381
 0.008618
 0.009201
 0.011191
 0.012050
 0.002797
 0.014556
 0.009948
 0.015311
 0.007481
 0.012336
 0.018282
 0.015769
 0.022537
 0.012794
 0.011110
 0.014009
 0.008554
 0.004643
 0.013591
 0.007173
 0.011444
 0.021132
 0.012940
 0.024820
 0.010027
 0.007681
 0.009216
 0.009933
 0.003146
 0.015167
 0.023202
 0.010127
 0.007399
 0.020198
 0.014905
 0.006877
 0.004908
 0.026132
 0.012022
 0.016704
 0.009139
 0.006666
 0.003778
 0.026920
 0.012163
 0.013676
 0.006858
 0.015185
 0.010753
 0.025602
 0.007955
 0.010976
 0.013156
 0.003516
 0.010513
 0.018284
 0.018212
 0.010992
 0.012962
 0.014529
 0.028408
 0.027240
 0.013631
 0.020987
 0.010640
 0.004354
 0.007871
 0.002759
 0.007288
 0.026339
 0.007701
 0.016238
 0.031080
 0.006225
 0.009353
 0.014921
 0.007886
 0.013186
 0.021266
 0.004881
 0.008920
 0.009042
 0.014256
 0.006553
 0.009761
 0.056092
 0.025113
 0.032900
 0.011843
 0.011996
 0.010642
 0.016676
 0.010579
 0.007957
 0.012955
 0.013691
 0.017115
 0.015779
 0.009554
 0.028190
 0.012810
 0.013217
 0.011130
 0.029676
 0.021497
 0.008109
 0.003882
 0.013387
 0.020356
 0.007011
 0.014245
 0.005117
 0.003302
 0.010415
 0.001282
 0.009526
 0.012404
 0.028545
 0.006146
 0.005232
 0.008368
 0.007169
 0.021519
 0.015523
 0.012725
 0.007932
 0.006366
 0.011487
 0.012199
 0.002971
 0.014476
 0.019623
 0.003481
 0.007831
 0.010449
 0.020860
 0.008323
 0.013370
 0.005658
 0.019046
 0.009889
 0.024582
 0.007778
 0.007585
 0.005952
 0.006543
 0.020796
 0.013027
 0.005928
 0.013782
 0.017549
 0.011934
 0.006887
 0.008550
 0.014508
 0.012039
 0.014317
 0.003982
 0.007541
 0.004488
 0.014768
 0.009293
 0.016703
 0.007881
 0.010466
 0.012855
 0.007138
 0.018107
 0.010545
 0.003692
 0.007024
 0.007345
 0.014200
 0.016324
 0.010162
 0.010048
 0.002663
 0.003232
 0.015476
 0.009884
 0.022988
 0.011652
 0.017621
 0.005588
 0.007840
 0.007766
 0.013995
 0.021798
 0.012141
 0.014956
 0.024336
 0.007827
 0.027227
 0.010948
 0.010062
 0.005162
 0.015367
 0.010307
 0.006901
 0.009148
 0.006537
 0.019215
 0.014714
 0.014921
 0.013632
 0.007576
 0.008931
];
loss(length(loss):length(loss3))= NaN;
loss2(length(loss2):length(loss3))= NaN;
plot(1:16:16*length(loss3),loss3,'LineWidth',2)
ylabel('Cross Entropy Loss')
xlabel('Iteration Number')
%%
loss_256 = [0.03491373159226001 0.011827537337456479 0.012234764807895614 0.01021996247127247 ];
loss_128=[0.13872451788386492 0.012961552783046615 0.01280779115636613 0.010203562263351467];
loss_64=[0.2611253304392334 0.017942624453979535 0.013578898802318969 0.010853669161656936];
iter = [200 5000 10000 20000];
a =plot(iter,loss_256,'LineWidth',2);
ax = gca;
ax.XAxis.TickLabelFormat = '%4d';
ax.XAxis.Exponent = 0;
hold on
plot(iter,loss_128,'LineWidth',2)
hold on
plot(iter,loss_64,'LineWidth',2)
set(gca,'xtick',iter)
legend('Feature Depth: 256','Feature Depth: 128','Feature Depth: 64')
ylabel('Cross Entropy Loss (average)')
xlabel('Number of Iterations')